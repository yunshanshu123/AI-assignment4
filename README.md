# AI-assignment4
```markdown
# 大语言模型对比分析实验报告

## 项目概述
本项目对通义千问和Chatglm两款大语言模型进行了横向对比测试，通过5类典型问题评估其在语义理解、逻辑分析、结构化表达等方面的表现。

## 项目地址
🔗 [GitHub仓库链接](https://github.com/yunshanshu123/AI-assignment4.git)

## 测试问题
1. 季节与穿衣的语义理解
2. 单身狗原因的幽默双关
3. 多层嵌套的指代关系
4. 人名与语义的歧义解析
5. "意思"的多义性解析

## 关键发现

### 语义理解能力
| 维度               | 通义千问 | Chatglm |
|--------------------|----------|---------|
| 语境分析深度       | ★★★★☆    | ★★☆☆☆   |
| 双关语解析         | ★★★★☆    | ★★☆☆☆   |
| 字面逻辑理解       | ★★☆☆☆    | ★★★★☆   |

### 典型场景表现
```diff
+ 通义千问优势场景：
- 深层语义分析（如问题1、2）
- 歧义句解析（如问题4）
- 幽默双关理解

+ Chatglm优势场景：
- 逻辑问题拆解（如问题3）
- 结构化表达（如问题5）
- 技术文档处理
```

## 部署说明
1. 克隆仓库：
```bash
git clone https://github.com/yunshanshu123/AI-assignment4.git
```
2. 环境配置：
```bash
pip install -r requirements.txt
```

## 结果示例
### 通义千问回答示例
![问题1回答](media/image3.png)
![问题4回答](media/image7.png)

### Chatglm回答示例
![问题3回答](media/image11.png)
![问题5回答](media/image13.png)

## 使用建议
| 使用场景               | 推荐模型     |
|------------------------|--------------|
| 广告文案分析           | 通义千问     |
| 社交语言理解           | 通义千问     |
| 技术文档解析           | Chatglm      |
| 会议纪要生成           | Chatglm      |

## 改进建议
- 通义千问：精简重复内容，提升回答简洁性
- Chatglm：增强对语言微妙之处的捕捉能力

## 贡献者
[@yunshanshu123](https://github.com/yunshanshu123)

```

这个README文件：
1. 采用清晰的Markdown语法
2. 包含可视化对比表格和标签
3. 突出核心发现和推荐场景
4. 提供部署指引和示例
5. 使用emoji和diff语法增强可读性
6. 保持专业简洁的风格
